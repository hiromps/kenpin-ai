import { useEffect, useRef, useState, useCallback } from 'react';
import { analyzeImage } from '../utils/imageAnalysis';
import { DefectDetail } from '../types/inspection';

interface RealtimeScanningOptions {
  videoRef: React.RefObject<HTMLVideoElement>;
  overlayCanvasRef: React.RefObject<HTMLCanvasElement>;
  isActive: boolean;
  onDefectDetected: (defects: DefectDetail[], imageDataUrl: string) => void;
  scanInterval?: number; // „Éü„É™ÁßíÂçò‰Ωç„ÅÆ„Çπ„Ç≠„É£„É≥ÈñìÈöîÔºà„Éá„Éï„Ç©„É´„Éà: 500msÔºâ
  focusPoint?: { x: number; y: number } | null; // „Çø„ÉÉ„Éó„Åó„Åü‰ΩçÁΩÆÔºà0-1„ÅÆÁØÑÂõ≤Ôºâ
}

export const useRealtimeScanning = ({
  videoRef,
  overlayCanvasRef,
  isActive,
  onDefectDetected,
  scanInterval = 500,
  focusPoint = null,
}: RealtimeScanningOptions) => {
  const [isScanning, setIsScanning] = useState(false);
  const [lastScanTime, setLastScanTime] = useState(0);
  const animationFrameRef = useRef<number>();
  const canvasRef = useRef<HTMLCanvasElement | null>(null);

  // „Éè„Ç§„É©„Ç§„Éà„ÇíÊèèÁîª„Åô„ÇãÈñ¢Êï∞
  const drawHighlights = useCallback((defects: DefectDetail[]) => {
    if (!overlayCanvasRef.current || !videoRef.current) return;

    const canvas = overlayCanvasRef.current;
    const video = videoRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    // „Ç≠„É£„É≥„Éê„Çπ„Çµ„Ç§„Ç∫„ÇíÂãïÁîª„Çµ„Ç§„Ç∫„Å´Âêà„Çè„Åõ„Çã
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    // Êó¢Â≠ò„ÅÆÊèèÁîª„Çí„ÇØ„É™„Ç¢
    ctx.clearRect(0, 0, canvas.width, canvas.height);

    // ÂêÑÊ¨†Èô•„ÅÆ„Éè„Ç§„É©„Ç§„Éà„ÇíÊèèÁîª
    defects.forEach((defect) => {
      if (!defect.location) return;

      const { x, y, width, height } = defect.location;

      // Ê¨†Èô•„Çø„Ç§„Éó„Å´Âøú„Åò„ÅüËâ≤„ÇíË®≠ÂÆö
      let color = '#ef4444'; // Ëµ§Ôºà„Éá„Éï„Ç©„É´„ÉàÔºâ
      if (defect.type === 'ÈªíÁÇπ') {
        color = '#ef4444'; // Ëµ§
      } else if (defect.type === '„Ç≠„Ç∫') {
        color = '#f97316'; // „Ç™„É¨„É≥„Ç∏
      } else if (defect.type === '„Éï„É©„ÉÉ„Ç∑„É•') {
        color = '#eab308'; // ÈªÑËâ≤
      }

      // Áü©ÂΩ¢„ÇíÊèèÁîª
      ctx.strokeStyle = color;
      ctx.lineWidth = 4;
      ctx.strokeRect(x, y, width, height);

      // ÂçäÈÄèÊòé„ÅÆËÉåÊôØ
      ctx.fillStyle = color + '40'; // 25%ÈÄèÊòéÂ∫¶
      ctx.fillRect(x, y, width, height);

      // „É©„Éô„É´„ÇíÊèèÁîª
      ctx.fillStyle = color;
      ctx.font = 'bold 24px Arial';
      const label = `${defect.type} ${(defect.confidence * 100).toFixed(0)}%`;
      const textMetrics = ctx.measureText(label);
      const textX = x;
      const textY = y - 10;

      // „É©„Éô„É´ËÉåÊôØ
      ctx.fillRect(textX, textY - 24, textMetrics.width + 10, 30);

      // „É©„Éô„É´„ÉÜ„Ç≠„Çπ„Éà
      ctx.fillStyle = '#ffffff';
      ctx.fillText(label, textX + 5, textY);
    });
  }, [overlayCanvasRef, videoRef]);

  // „Éè„Ç§„É©„Ç§„Éà„Çí„ÇØ„É™„Ç¢„Åô„ÇãÈñ¢Êï∞
  const clearHighlights = useCallback(() => {
    if (!overlayCanvasRef.current) return;

    const canvas = overlayCanvasRef.current;
    const ctx = canvas.getContext('2d');
    if (!ctx) return;

    ctx.clearRect(0, 0, canvas.width, canvas.height);
  }, [overlayCanvasRef]);

  const captureFrame = useCallback((): string | null => {
    if (!videoRef.current) return null;

    const video = videoRef.current;

    // „Ç≠„É£„É≥„Éê„Çπ„ÅåÂ≠òÂú®„Åó„Å™„ÅÑÂ†¥Âêà„ÅØ‰ΩúÊàê
    if (!canvasRef.current) {
      canvasRef.current = document.createElement('canvas');
    }

    const canvas = canvasRef.current;
    const context = canvas.getContext('2d');
    if (!context) return null;

    // „Éï„Ç©„Éº„Ç´„Çπ„Éù„Ç§„É≥„Éà„ÅåÊåáÂÆö„Åï„Çå„Å¶„ÅÑ„ÇãÂ†¥Âêà„ÅØ„ÄÅ„Åù„ÅÆÂë®Ëæ∫È†òÂüü„ÅÆ„Åø„ÇíÂàá„ÇäÂá∫„Åô
    if (focusPoint) {
      // „Éï„Ç©„Éº„Ç´„ÇπÈ†òÂüü„ÅÆ„Çµ„Ç§„Ç∫Ôºà„Éì„Éá„Ç™„ÅÆ40%Ôºâ
      const focusSize = 0.4;
      const focusWidth = video.videoWidth * focusSize;
      const focusHeight = video.videoHeight * focusSize;

      // „Éï„Ç©„Éº„Ç´„Çπ„Éù„Ç§„É≥„Éà„Çí‰∏≠ÂøÉ„Å®„Åó„ÅüÈ†òÂüü„ÅÆÂ∫ßÊ®ô
      const sx = Math.max(0, video.videoWidth * focusPoint.x - focusWidth / 2);
      const sy = Math.max(0, video.videoHeight * focusPoint.y - focusHeight / 2);
      const sw = Math.min(focusWidth, video.videoWidth - sx);
      const sh = Math.min(focusHeight, video.videoHeight - sy);

      canvas.width = sw;
      canvas.height = sh;

      // ÊåáÂÆöÈ†òÂüü„ÅÆ„Åø„ÇíÊèèÁîª
      context.drawImage(video, sx, sy, sw, sh, 0, 0, sw, sh);

      console.log(`üéØ „Éï„Ç©„Éº„Ç´„ÇπÊ§úÂá∫„É¢„Éº„Éâ: ‰∏≠ÂøÉ(${(focusPoint.x * 100).toFixed(0)}%, ${(focusPoint.y * 100).toFixed(0)}%) È†òÂüü„Çµ„Ç§„Ç∫: ${sw.toFixed(0)}x${sh.toFixed(0)}px`);
    } else {
      // „Éï„Ç©„Éº„Ç´„Çπ„Éù„Ç§„É≥„Éà„ÅåÊåáÂÆö„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑÂ†¥Âêà„ÅØÂÖ®ÁîªÈù¢
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      context.drawImage(video, 0, 0);
    }

    return canvas.toDataURL('image/jpeg', 0.8);
  }, [videoRef, focusPoint]);

  const scanFrame = useCallback(async () => {
    if (!isActive || !videoRef.current) return;

    const now = Date.now();

    // „Çπ„Ç≠„É£„É≥ÈñìÈöî„ÉÅ„Çß„ÉÉ„ÇØ
    if (now - lastScanTime < scanInterval) {
      animationFrameRef.current = requestAnimationFrame(scanFrame);
      return;
    }

    setIsScanning(true);
    setLastScanTime(now);

    try {
      const imageDataUrl = captureFrame();
      if (!imageDataUrl) {
        setIsScanning(false);
        animationFrameRef.current = requestAnimationFrame(scanFrame);
        return;
      }

      // Ê¨†Èô•Ê§úÂá∫
      const defects = await analyzeImage(imageDataUrl);

      // Ê¨†Èô•„ÅåË¶ã„Å§„Åã„Å£„ÅüÂ†¥Âêà
      if (defects.length > 0) {
        drawHighlights(defects); // „Éè„Ç§„É©„Ç§„ÉàË°®Á§∫
        onDefectDetected(defects, imageDataUrl);
        setIsScanning(false);
        return; // „Çπ„Ç≠„É£„É≥„ÇíÂÅúÊ≠¢
      } else {
        clearHighlights(); // „Éè„Ç§„É©„Ç§„Éà„Çí„ÇØ„É™„Ç¢
      }
    } catch (error) {
      console.error('„Çπ„Ç≠„É£„É≥„Ç®„É©„Éº:', error);
    }

    setIsScanning(false);
    animationFrameRef.current = requestAnimationFrame(scanFrame);
  }, [isActive, videoRef, lastScanTime, scanInterval, captureFrame, onDefectDetected, drawHighlights, clearHighlights]);

  useEffect(() => {
    if (isActive && videoRef.current) {
      // „Çπ„Ç≠„É£„É≥ÈñãÂßã
      animationFrameRef.current = requestAnimationFrame(scanFrame);
    } else {
      // „Çπ„Ç≠„É£„É≥ÂÅúÊ≠¢
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    }

    return () => {
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (canvasRef.current) {
        canvasRef.current = null;
      }
    };
  }, [isActive, videoRef, scanFrame]);

  return { isScanning };
};
